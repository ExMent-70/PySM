### **Руководство по "GPU System Report" (v1.05.03)**

#### **1. Назначение**

Этот скрипт представляет собой утилиту для сбора и отображения исчерпывающей информации о графической подсистеме NVIDIA и связанных с ней библиотеках (`PyTorch`, `CUDA`, `cuDNN`). Он позволяет получить единый, легко читаемый отчет, который помогает понять текущую конфигурацию системы и диагностировать проблемы совместимости.

**Когда следует использовать этот скрипт:**
*   Для получения точных версий всех компонентов стека GPU перед установкой нового ПО.
*   При диагностике проблем, когда PyTorch не может использовать GPU.
*   Для инвентаризации аппаратных и программных ресурсов на рабочем месте или сервере.

#### **2. Логика работы**

Скрипт последовательно опрашивает различные источники для сбора информации:

1.  **Библиотека `pynvml`:** Используется для прямого взаимодействия с API драйвера NVIDIA (NVIDIA Management Library). Отсюда получается самая низкоуровневая информация:
    *   Версия установленного драйвера.
    *   Максимальная версия CUDA, которую этот драйвер поддерживает.
    *   Количество и название физических видеокарт.
    *   Информация о памяти, температуре и вычислительной способности каждого устройства.

2.  **Библиотека `torch`:** Используется для получения информации с точки зрения самого PyTorch:
    *   Установленная версия PyTorch.
    *   Версия CUDA, с которой был **скомпилирован** PyTorch.
    *   Версия библиотеки cuDNN, с которой он связан.

Собранные данные выводятся в консоль PySM в структурированном виде.

#### **3. Интерпретация результатов**

Каждый раздел отчета дает важную информацию:

*   **Версия драйвера NVIDIA:** Версия вашего системного драйвера. Это основа всего стека.

*   **Версия CUDA (поддерживаемая драйвером):** Это **максимальная** версия CUDA API, которую может обслуживать ваш текущий драйвер. Например, `12.2`.

*   **Версия PyTorch CUDA:** Это версия CUDA, с которой **был собран** ваш PyTorch. Например, `11.8`. **Это ключевой момент для совместимости:** версия PyTorch CUDA **должна быть меньше или равна** версии CUDA, поддерживаемой драйвером. Если у вас драйвер поддерживает максимум CUDA 11.2, а PyTorch собран с CUDA 11.8, он работать не будет.

*   **Версия CUDNN:** Версия библиотеки NVIDIA для ускорения глубоких нейронных сетей, которую использует PyTorch.

*   **Информация по устройствам:**
    *   **Название:** Модель вашей видеокарты.
    *   **Память:** Объем используемой и общей видеопамяти.
    *   **Вычислительная способность (Compute Capability):** Версия архитектуры GPU (например, 8.6 для RTX 30xx). Определяет поддержку тех или иных аппаратных функций (например, тензорных ядер определенного поколения).
    *   **Температура:** Текущая температура графического процессора.

#### **4. Параметры**

Данный скрипт не принимает параметров командной строки.

#### **5. Требования**

Для корректной работы скрипта необходимо, чтобы в вашем Python-окружении были установлены следующие библиотеки:

*   **`torch`**: Библиотека PyTorch.
*   **`pynvml`**: Python-обертка для NVIDIA Management Library. Устанавливается командой `pip install pynvml`.

---


### **Полное руководство по установке стека NVIDIA**

#### **Философия и порядок действий**

Ключ к успеху — строгая последовательность. Компоненты зависят друг от друга как матрешка. Нельзя установить PyTorch для CUDA 12.1, если у вас драйвер поддерживает только CUDA 11.8.

**Правильный порядок установки:**
1.  **Драйвер NVIDIA** (Фундамент)
2.  **CUDA Toolkit** (Зависит от драйвера и потребностей библиотек)
3.  **cuDNN** (Зависит от версии CUDA Toolkit)
4.  **Python-библиотеки** (`torch`, `tensorrt`) (Зависят от CUDA Toolkit и cuDNN)

---

#### **Шаг 1: Установка/Обновление драйвера NVIDIA**

Это самый важный шаг. Драйвер определяет, какую максимальную версию CUDA вы можете использовать.

1.  **Перейдите на официальный сайт NVIDIA для загрузки драйверов по адресу:**
    `https://www.nvidia.com/Download/index.aspx`
2.  **Выберите вашу видеокарту:** Укажите серию (например, GeForce RTX 30 Series) и модель (например, GeForce RTX 3080).
3.  **Тип загрузки:** Выбирайте **"Studio Driver (SD)"**, если ваша основная цель — разработка и стабильность. Выбирайте "Game Ready Driver (GRD)", если вы также играете в игры (он тоже отлично подходит для разработки).
4.  **Скачайте и установите:**
    *   Запустите скачанный установщик.
    *   Выберите **"Выборочная установка (дополнительные параметры)"**.
    *   На следующем экране **обязательно поставьте галочку "Выполнить чистую установку"**. Это удалит старые профили и настройки, предотвращая возможные конфликты.
5.  **Перезагрузите компьютер** после завершения установки.

**Проверка:** После перезагрузки откройте командную строку (cmd) и введите `nvidia-smi`. Если вы видите таблицу с информацией о вашей видеокарте и версии драйвера — все прошло успешно. Обратите внимание на версию CUDA, указанную в правом верхнем углу (например, `CUDA Version: 12.2`). Это **максимальная** версия, которую поддерживает ваш драйвер.

---

#### **Шаг 2: Установка CUDA Toolkit**

##### **2.1. Определитесь с версией CUDA Toolkit**

Перед установкой CUDA Toolkit вам необходимо выбрать его версию. Эта версия должна быть совместима как с PyTorch, так и с TensorRT, которые вы планируете использовать. Вот как найти эту информацию.

*   **Поиск совместимости для PyTorch**
    Самый простой способ — использовать официальную страницу установки PyTorch.
    *   **Адрес страницы:** `https://pytorch.org/get-started/locally/`
    *   **Как найти информацию:**
        1.  На этой странице есть интерактивный конфигуратор "START LOCALLY".
        2.  Выберите ваши параметры: `Stable` (стабильная версия), вашу ОС (например, `Windows`), `Pip`, `Python`.
        3.  В разделе **"Compute Platform"** вы увидите список доступных версий CUDA, например, `CUDA 11.8` и `CUDA 12.1`. Это те версии, для которых существуют официальные, протестированные сборки последней версии PyTorch.
        4.  Запомните или запишите эти версии. Например, **PyTorch (latest) -> поддерживает CUDA 11.8 и 12.1**.

*   **Поиск совместимости для TensorRT**
    Информация о совместимости TensorRT находится в официальной документации NVIDIA.
    *   **Адрес основного портала документации:** `https://docs.nvidia.com/deeplearning/tensorrt/index.html`
    *   **Как найти информацию:**
        1.  Перейдите по указанному адресу.
        2.  В меню слева найдите и кликните по разделу **"Release Notes"** (Примечания к выпуску).
        3.  На открывшейся странице выберите последнюю версию TensorRT (например, "TensorRT 9.x Release Notes").
        4.  Внутри документации по версии найдите раздел под названием **"Support Matrix"** (Матрица поддержки).
        5.  В этой таблице будет четко указано, какие версии CUDA Toolkit, cuDNN и драйверов требуются для данной версии TensorRT.

*   **Принятие решения: Поиск пересечения**
    Теперь у вас есть два набора данных. Ваша задача — **найти версию CUDA, которая присутствует в списках поддержки ОБЕИХ библиотек.**
    *   **Пример сценария:**
        1.  Вы посмотрели на сайте PyTorch и увидели, что последняя версия поддерживает **CUDA 11.8** и **CUDA 12.1**.
        2.  Вы посмотрели "Support Matrix" для последней версии TensorRT и увидели, что она требует **CUDA 12.2**. Пересечения нет.
        3.  Вы смотрите "Support Matrix" для предыдущей версии TensorRT (например, 8.6.1) и видите, что она требует **CUDA 11.8**.
        4.  **Вывод:** **CUDA 11.8** — это ваш идеальный кандидат. Он поддерживается и PyTorch, и одной из версий TensorRT. Именно эту версию CUDA Toolkit вам и следует устанавливать.

##### **2.2. Скачивание и установка CUDA Toolkit**

1.  **Перейдите в архив CUDA Toolkit по адресу:**
    `https://developer.nvidia.com/cuda-toolkit-archive`
2.  **Выберите нужную версию** (в нашем примере — 11.8.0).
3.  **Выберите вашу ОС** и тип установщика (рекомендуется `exe (local)` для Windows).
4.  **Скачайте и установите:**
    *   Запустите установщик.
    *   Выберите **"Выборочная установка"**.
    *   **ОЧЕНЬ ВАЖНО:** На экране выбора компонентов снимите галочку с компонента **"Display Driver" / "GeForce Experience"** и всего, что связано с драйвером. Мы уже установили самый свежий драйвер на Шаге 1, и установщик CUDA может попытаться установить более старую версию, что приведет к проблемам. Оставьте только сам **"CUDA"** и другие необходимые компоненты.

---

#### **Шаг 3: Установка cuDNN**

cuDNN — это библиотека для ускорения нейронных сетей, которая "добавляется" в CUDA Toolkit.

1.  **Перейдите в архив cuDNN по адресу:**
    `https://developer.nvidia.com/rdp/cudnn-archive`
    *(Для доступа потребуется бесплатная учетная запись NVIDIA Developer).*
2.  **Выберите версию cuDNN, совместимую с вашей версией CUDA Toolkit.** На странице загрузки будет явно написано, например, "Download cuDNN v8.9.7 (December 5th, 2023), for CUDA 11.x".
3.  **Скачайте архив** (ZIP-файл) для вашей версии CUDA.
4.  **Распакуйте архив.** Внутри вы увидите папки `bin`, `include`, `lib`.
5.  **Скопируйте файлы:** Вам нужно скопировать содержимое этих папок в соответствующие папки внутри установленного CUDA Toolkit.
    *   По умолчанию, CUDA Toolkit устанавливается в `C:\Program Files\NVIDIA GPU Computing Toolkit\CUDA\v11.8` (замените `v11.8` на вашу версию).
    *   Откройте папку с распакованным cuDNN.
    *   Скопируйте содержимое папки `bin` в `C:\...CUDA\v11.8\bin`.
    *   Скопируйте содержимое папки `include` в `C:\...CUDA\v11.8\include`.
    *   Скопируйте содержимое папки `lib\x64` в `C:\...CUDA\v11.8\lib\x64`.

---

#### **Шаг 4: Установка Python-библиотек (в виртуальном окружении)**

Теперь, когда системная часть готова, устанавливаем Python-пакеты. **Настоятельно рекомендуется делать это в виртуальном окружении.**

1.  **Создайте и активируйте виртуальное окружение:**
    ```bash
    python -m venv .venv
    .venv\Scripts\activate  # Для Windows
    source .venv/bin/activate # Для Linux/macOS
    ```

2.  **Установка PyTorch:**
    *   Перейдите на официальный сайт PyTorch для генерации команды установки по адресу:
        `https://pytorch.org/get-started/locally/`
    *   Используйте конфигуратор на странице, чтобы выбрать `Stable`, вашу ОС, `Pip`, `Python` и нужную версию CUDA (ту, которую вы установили на Шаге 2, например, CUDA 11.8).
    *   Скопируйте сгенерированную команду. Она будет выглядеть примерно так:
        ```bash
        pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
        ```
    *   Выполните эту команду в вашем активированном виртуальном окружении.

3.  **Установка TensorRT:**
    *   Установка TensorRT через `pip` — самый простой способ. Пакет будет установлен из специального репозитория NVIDIA.
    *   Выполните команду:
        ```bash
        pip install --upgrade "tensorrt" --find-links https://pypi.ngc.nvidia.com
        ```
    *   Эта команда автоматически найдет и установит версию TensorRT, совместимую с вашим окружением.

---

#### **Шаг 5: Финальная проверка**

Теперь, когда все установлено, используйте диагностические скрипты PySM, чтобы убедиться, что все работает:

1.  **Запустите `run_gpu_report.py`**. Убедитесь, что все версии (драйвер, CUDA драйвера, PyTorch CUDA, CUDNN) отображаются корректно и соответствуют тому, что вы устанавливали.
2.  **Запустите `run_py_torch_doctor.py`**. Он должен завершиться с сообщением `✅✅✅ ULTIMATE SUCCESS`.
3.  **Запустите `run_tensorrt_doctor.py`**. Он тоже должен завершиться с сообщением `✅✅✅ ПОЛНЫЙ УСПЕХ`.

Если все три проверки прошли успешно — ваша среда NVIDIA для машинного обучения полностью настроена и готова к работе.